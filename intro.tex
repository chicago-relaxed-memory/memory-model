\section{Introduction}
\label{sec:intro}
\citet{Manson:2005:JMM:1047659.1040336} identify the central problem in the
design of software relaxed memory models: ``The memory model must strike a
balance between ease-of-use for programmers and implementation flexibility
for system designers.''  

%In order to sharpen the criteria to evaluate memory models, we first outline desiderata  that concretize the above prescription.  

There are two aspects to ``ease of use.''  First, programs should support
\emph{compositional} and \emph{local} reasoning; in this paper, we emphasize
temporal safety
properties~\cite{PnueliSafety,Misra:1981:PNP:1313338.1313770,StarkSafety,Abadi:1993:CS:151646.151649}.
Second, relaxed memory should be not change the behavior of correctly
synchronized programs; this property is known as \emph{sequential consistency
  for data race free programs} (\drfsc)~\cite{DBLP:journals/tpds/AdveH93,
  DBLP:conf/isca/AdveH90}.
 % Second, the expectation of
% \emph{sequential consistency for data race free programs}
% (\drfsc)~\cite{DBLP:journals/tpds/AdveH93, DBLP:conf/isca/AdveH90} permits
% the programmer to forget about relaxed memory for correctly synchronized
% programs.

% There are two aspects to ``ease of use.''  First, programmers should be able
% to reason about program fragments \emph{compositionally} and \emph{locally};
% in this paper we emphasize compositional reasoning about temporal safety
% properties~\cite{PnueliSafety,Misra:1981:PNP:1313338.1313770,StarkSafety,Abadi:1993:CS:151646.151649}.
% Second, programmers should be able to forget about relaxed memory in
% correctly synchronized programs; this property is known as \emph{sequential
%   consistency for data race free programs}
% (\drfsc)~\cite{DBLP:journals/tpds/AdveH93, DBLP:conf/isca/AdveH90}.

There are also two aspects of ``implementation flexibility.''  First, relaxed
atomic access should not require hardware synchronization (at least for the
word size of the machine).  Second, the model
should facilitate compiler transformations, such as the reordering of independent
statements; ideally the model should support all %valid
optimizations of
synchronization\hyp{}free single\hyp{}threaded code.
% A
% canonical example is that independent statements should commute.

Sailing between this Scylla and Charybdis has proven very difficult.  Three
lines of code can leave the top experts in the field flabbergasted.  The
solutions that have been proposed are understandable to mechanical proof
assistants, but humans have been left behind.

In this paper, we combine two ideas that humans can understand: \emph{preconditions}
\cite{Hoare:1969:ABC:363235.363259} and \emph{labelled partial orders} (aka \emph{pomsets})
\cite{GISCHER1988199,Plotkin:1997:TSP:266557.266600}.  The resulting model
mostly satisfies the desiderata.  We sacrifice only implementability on
``non-\mca'' processors, such as \ppc\ and \armseven{}. As a result, however,
there is only one order relation to visualize.

Perhaps you believe the problem has already been solved?  Let us try to
convince you otherwise.
% Eventually,
% the enthusiasm of proposing a new model yields to weariness as the
% complications mount.

To get a sense of the difficulties involved,
% \citeauthor{DBLP:journals/toplas/Lochbihler13}'s example shows a surprising feature of
% relaxed memory models: the presence of an execution may depend on code that was not executed. Consider:
consider that the existence of an execution in a relaxed memory model may
depend on code that was \emph{not} executed. Let $r$--$s$ be registers and
$b$, $x$--$z$ be shared memory locations.  Consider the following program, where
all memory locations are initialized to $0$:
\begin{align*}
  \tag{\ref{OOTA?}}
    y\GETS x
  \PAR&
  r\GETS y\SEMI\IF{r}\THEN 
  x\GETS r\SEMI z\GETS r \ELSE x\GETS1 \FI
\intertext{Most programmers would be surprised to learn that this program does allow an
execution in which $z{=}1$. To see why, imagine that a compiler does type
inference and finds that $x$ and $y$ are booleans, with value either $0$ or
$1$.  This enables the program to be optimized to the following:}
  %\taglabelp{OOTA?}
    y\GETS x
  \PAR&
  r\GETS y\SEMI\IF{r}\THEN 
  x\GETS 1\SEMI z\GETS 1 \ELSE x\GETS1 \FI
\intertext{Since $x\GETS1$ occurs in both branches of the conditional, the compiler can
then lift it, and reorder with the independent read of $y$, yielding:}
  %\taglabelpp{OOTA?}
    y\GETS x
  \PAR&
  x\GETS1\SEMI
  r\GETS y\SEMI\IF{r}\THEN z\GETS 1 \FI
\intertext{Then $z{=}1$ at then end of an execution where the first thread is interleaved
immediately after executing $x\GETS1$.
Without the conditional in \eqref{OOTA?}, it is obvious that the program should not write $1$:}
  \tag{\ref{OOTA3}}
  %x\GETS0\SEMI y\GETS0\SEMI
  %(\bLoc \GETS \aLoc \PAR \aLoc \GETS \bLoc)
  \bLoc \GETS \aLoc \PAR&
  r\GETS y\SEMI x\GETS r  \SEMI z\GETS r
\end{align*}
In \ref{OOTA3}, the constant $1$ arises ``Out Of Thin Air'' (\oota)
\cite{DBLP:conf/esop/BattyMNPS15}.  As a result, any model of relaxed memory
that supports common compiler optimizations, as above, must take into account
code that was not executed.  This is why many models of relaxed memory
include some form of speculative execution, with the goal of allowing the
outcome $z{=}1$ for \eqref{OOTA?}, but not \ref{OOTA3}.

The control flow variant of \ref{OOTA3} is:
\begin{displaymath}
  \label{cyc}\tag{\textsc{oota2}}
  \IF{x}\THEN y\GETS 1 \FI \!\PAR\! \IF{y}\THEN x\GETS 1 \SEMI z\GETS 1\FI
\end{displaymath}
This program is data-race-free. Thus, allowing an execution that writes $1$
would violate \drfsc{}.


\oota{} behaviors can be quite subtle.
Consider the following variants of \eqref{OOTA?}:
\begin{align}
  \tag{\ref{OOTA!}}
    y\GETS x
  \PAR&
  r\GETS y\SEMI \IF{r}\THEN 
  x\GETS r\SEMI z\GETS r \ELSE x\GETS2 \FI
  \\
  \tag{\ref{OOTA4}}
  y\GETS x
  \PAR&
  r\GETS y \SEMI \IF{b}\THEN  x\GETS r \SEMI z\GETS r \ELSE x\GETS1 \FI
  \PAR
  b\GETS1
\end{align}
Following the reasoning above, \eqref{OOTA!} has an execution where
$z{=}2$, but it does not have an execution where $z{=}1$.   Neither does
\ref{OOTA4}.  In this case, it not sound to assume that  $1$ is
written on both sides of the conditional, invalidating the first optimization
given for \eqref{OOTA?} above.
% Note that the only
% difference between \eqref{OOTA?} and \eqref{OOTA!} is the code in the branch
% that was not taken.  
  

% Many models of relaxed
% memory include some form of speculative execution in order to allow $1$ in
% \eqref{OOTA?}, but not \eqref{OOTA!} and \ref{OOTA3}.
% Any model of relaxed memory that supports common compiler optimizations
% (such as the transformations above) must take into account code that was
% not executed. This is why many models of relaxed memory include some form
% of speculative execution.

% Any model of relaxed memory that supports common compiler optimizations, as
% above, must take into account code that was not executed.  This is why many
% models of relaxed memory include some form of speculative execution, with the
% goal of allowing $1$ in \eqref{OOTA?}, but not \eqref{OOTA!} and
% \ref{OOTA3}.
% Many models of relaxed memory include some form of speculative execution in
% order to allow $1$ in \eqref{OOTA?}, but not \eqref{OOTA!} and
% \ref{OOTA3}.


\citeauthor{DBLP:conf/java/Pugh99} [\citeyear{DBLP:conf/java/Pugh99},
\textsection2.3] initiated the modern study of relaxed memory by noting that
Java 1.1 failed to validate Common Subexpression Elimination (CSE) in the
presence of aliasing. For example, given that $\aReg_2{\neq}\bReg$, is it valid
to transform the program on the left to that on the right?
\begin{align*}
  %\tag{\ref{CSE}}
  ({r_1\GETS \aLoc \SEMI
  s\GETS \bLoc \SEMI  
  r_2\GETS \aLoc\SEMI\aCmd})
&&
  ({r_1\GETS \aLoc \SEMI     
    r_2\GETS r_1\SEMI
    s\GETS \bLoc \SEMI\aCmd})
\end{align*}
The resulting Java Memory Model (JMM) \cite{Manson:2005:JMM:1047659.1040336}
greatly advanced the state of the art.


\citeauthor{DBLP:journals/toplas/Lochbihler13}'s
monumental study of the JMM
revealed a surprising limitation. Consider the following program
\citep[Fig.~8]{DBLP:journals/toplas/Lochbihler13}, where again
all memory locations are initialized to $0$:
%\vspace{-.5ex}
\begin{gather}
  \tag{\textsc{oota5}}\label{OOTA1}
  y\GETS x
  \PAR
  \aReg\GETS y \SEMI \IF{b} \THEN \aReg \GETS \NEW \classD \SEMI x \GETS \aReg \SEMI z\GETS \aReg \ELSE \bReg \GETS \NEW \classC \SEMI x \GETS \aReg \FI  
  \PAR %\\[-1ex] \PAR&
  b \GETS 1
\end{gather}
\ref{OOTA1} ``is type correct if it declares $x$, $y$ and $r$ of type
$\classD$. However, it has a legal execution where they reference a $\classC$
object.''  The JMM allows $(\aReg\GETS y)$ to see the object created by
$\NEW$, by bouncing it through $(x \GETS \aReg)$ and $(y\GETS x)$.  This
allows the address of the allocated object to be read $(\aReg\GETS y)$ before
its type is determined $(\IF{b})$.

% See \ref{OOTA4} in
% \textsection\ref{sec:logic} for a simple variant of \eqref{OOTA?} with this
% behavior.

% By allowing such \emph{bait-and-switch} behaviors, the JMM fails to support
% compositional reasoning for temporal safety properties:  the individual
% threads of \ref{OOTA1} satisfy the invariant
% % \emph{allocation at type $\classD$ is preceded by reading zero for $b$}.
% % They also satisfy:
% \emph{allocation at type $\classC$ is preceded by reading $0$ for
%   $b$}, but the composed program does not.  This lack of compositionality

This type of {bait-and-switch} behavior forced
\citeauthor{DBLP:journals/toplas/Lochbihler13} to partition memory by type in
order to prove type safety.  This formal device means that memory cannot be
used at different types over time, making practical memory reclamation
impossible.  Even partitioning memory to achieve type safety, there are
implications for the Java security architecture
\cite[\textsection5.4]{DBLP:journals/toplas/Lochbihler13}.

In both \ref{OOTA4} and \ref{OOTA1}, the \oota{} outcome occurs by
\emph{baiting} with the \texttt{else} branch, then \emph{switching} to the
\texttt{then} branch.  As confirmed by \cite{kang,soham}, the promising
semantics \cite{DBLP:conf/popl/KangHLVD17} and related models
\citep{DBLP:conf/esop/JagadeesanPR10,DBLP:journals/pacmpl/ChakrabortyV19} all
allow \oota{} behaviors of \ref{OOTA4}\footnote{Call the threads \texttt{s},
  \texttt{t}, and \texttt{u}.  To get the result in the promising semantics,
  first execute \texttt{u} to get message \texttt{<b:1@1>}.  Then \texttt{t}
  promises \texttt{<x:1@1>}, which it can fulfill by reading \texttt{b==0}.
  Then execute \texttt{s} to get message \texttt{<y:1@1>}.  Then execute
  \texttt{t}, reading \texttt{b==1} and \texttt{y==1} and fulfill the promise
  by writing \texttt{<x:1@1>}.}.  Due to the similarity of \ref{OOTA4} and
\ref{OOTA1}, it is reasonable to conclude that these models \emph{cannot
  support both type safety and realistic memory reclamation}.

% The JMM is defined using an operational model that incorporates the idea of
% restarting executions.  Similar models have used speculation
% \cite{DBLP:conf/esop/JagadeesanPR10} or promises
% \cite{DBLP:conf/popl/KangHLVD17}.

% % Whereas the JMM was designed with these two aims,
% , invalidating compositional reasoning for temporal safety
% properties.
% % , as in
% % \ref{OOTA1}.  % (Specifically, they
% % allow the variant \ref{OOTA4} given in \textsection\ref{sec:logic}.)
% % See
% % \textsection\ref{sec:promising} for confirmation from the authors themselves.
% This means that these models \emph{cannot support both type safety and
%   realistic memory reclamation}.


% Due to the shortcomings of the JMM, many subsequent models preferred an
% axiomatic approach.  
The C11 Memory Model \cite{Batty:2011:MCC:1926385.1926394} does not attempt
to validate CSE, at least not for relaxed atomic access (consider the case
where $x$ and $y$ are aliased above).  C11 \emph{does} allow the
transformation for \emph{plain} access, but this comes with the threat of
\emph{undefined behavior} should any plain access ever possibly engage in a
data race \cite{undefined}.  C11 also allows \oota{} behaviors, exploiting
causality cycles.  Undefined/\oota{} behavior is antithetical to the goals of
safe languages.
% Thus the folklore belief that ``every substantial C program has
% undefined behavior.''


%to permit us to reason separately about individual threads validating safety properties. 
% ``Out Of Thin Air'' (\oota) executions invalidate the 
% composability  of safety properties.

% None of the extant memory models validate both
% ``implementation flexibility'' and ``ease of use.''  This paper provides a
% solution.  The solution is remarkably simple, enriching labelled partial
% orders (aka \emph{pomsets}) with preconditions.

Strong models, including Sequential Consistency
(SC)~\citep{Lamport:1979:MMC:1311099.1311750}, RC11
\citep{DBLP:conf/pldi/LahavVKHD17}, and others
\citep{Dolan:2018:BDR:3192366.3192421,DBLP:conf/pldi/LahavVKHD17,DBLP:conf/lics/JeffreyR16,Boehm:2014:OGA:2618128.2618134}
support compositional reasoning.  However, all of these models invalidate
reordering of independent statements.  Several require fences after relaxed
reads, even on \armeight.
% \cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA,DBLP:conf/lics/JeffreyR16} forbid breaking of the program order from reads to writes and thus require extra fences after read actions in hardware implementations.
% \citep{Boehm:2014:OGA:2618128.2618134} show that the RC11 model %\cite{DBLP:conf/pldi/LahavVKHD17}
% forces a dependency or a fence between a relaxed atomic read and a subsequent relaxed atomic write.  


\myparagraph{Our Model}

In our approach, a program is a set of executions.  Each execution is a
partial order on a set of read and write events.  The order is intended to be
read as a ``dependency'' relation.  The dependency relation can vary between
executions, so it is dynamic; events that are not related in an execution are
``independent'' and can be seen by a sequential observer in either order.

Cross thread dependencies arise from conflicting actions on the same
variable: Roughly, we order any two actions on the same location, at least
one of which is a write.  In the parlance of hardware memory
models~\citep{alglave}: $\rcoe$, $\rfre$, and $\rrfex$ are included in the
global dependency ordering.  Thus, our model realizes \emph{multi-copy
  atomicity} (\mca): when a write becomes visible to one thread it must
become visible to all\nofootnote{\mca\ is traditionally explored in hardware
  memory models.  \tso\ (see, e.g.~\cite{DBLP:journals/cacm/SewellSONM10})
  and recent architectures, such as \armeight\ (see,
  e.g.~\cite{DBLP:journals/pacmpl/PulteFDFSS18}, RISC-V.  ), are \mca, but
  not older architectures, such as \ppc\ (see,
  e.g.~\cite{DBLP:conf/pldi/SarkarSAMW11}) or \armseven\ (see,
  e.g.~\cite{DBLP:conf/popl/AlglaveFIMSSN09}).}
\citep{DBLP:journals/pacmpl/PulteFDFSS18}.  As envisioned in
\cite[\textsection3.3]{AlglaveThesis}, this allows us to capture cross-thread
dependencies in a single partial order.

Our key insight is that \emph{\mca{} permits a single, global notion of time,
  manifest in the pomset order}.
  

Within a thread, the dependency calculation can be viewed as the computation
of \emph{preserved} program order ($\rppo$) in hardware models.  $\rppo$
captures the \emph{essential dependencies} between events in the same thread.
Consider the following program fragments: \begingroup \allowdisplaybreaks
\begin{align*}
  & \aCmd^1: \aLoc \GETS 1 \SEMI \bLoc \GETS 1
  \\[-1ex] & \aCmd^2: \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN\ \bLoc \GETS 1 \ELSE \bLoc \GETS 1  \FI
  \\[-1ex] & \aCmd^3: \aLoc \GETS 1 \SEMI \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN \bLoc \GETS 1 \FI
  %\\[-1ex] &\aCmd^4:  \bLoc \GETS 1 \SEMI \aLoc \GETS 1
\end{align*}
\endgroup
All these fragments satisfy $\hoare{\TRUE}{\aCmd^i}{\bLoc =1}$; thus, in each
case, the write of $y$ is independent of any code that precedes it in program
order. While $\aCmd^1$ reflects syntactic independence, $\aCmd^2$ reflects
the independence derived by case analysis, and $\aCmd^3$ reflects the
independence deduced from partial evaluation (in the restricted form of
constant propagation).

Our key insight is to that \emph{logic is better than syntax} to capture such
dependencies.

The logical perspective provides a clear intuition as to why certain compiler
transformations should be valid.  Such intuitions are not always readily
available in relaxed memory models.  For example, \emph{value range
  analysis}---used in the discussion of \eqref{OOTA?}---is very difficult in
many models.  As another example, models such as \armeight{} distinguish
\emph{internal} reads, which are fulfilled by a write of the same thread,
from \emph{external} ones.  Unlike externally fulfilled reads, internal reads
are not necessarily recorded in the dependency relation.  As exemplified by
$\aCmd^3$, this allows a compiler to reorder the fulfilling write with
subsequent code that depends on the read.  Neither value range analysis nor
internal reads require special treatment in our model.



% The logical perspective provides a clear intuition as to why our model validates
% the compiler transformations discussed above \eqref{OOTA?}.
% reordering of independent statements, Irrelevant read introduction, RaR, RaW,
% WaW and Read Reordering and motivates the expressivity wrt the \jmm\
% causality test cases.  For example, consider Test Case 17 from Pugh.
% \[
% \begin{array}{ll}
%  &\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc \SEMI \bLoc \GETS \aReg_1  \\
%  \PAR & \aReg_2 \GETS \bLoc \SEMI \aLoc \GETS \aReg 
% \end{array}
% \]
% \jmm\ permits the behavior $\aReg_1 = \aReg_2 = \aReg_3 =42$.

% We deduce:
% \[
% \hoare{\TRUE}{\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc }{\aReg_1 =42}
% \]
% and so:
% \[
% \hoare{\TRUE}{\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc  \SEMI \bLoc \GETS \aReg_1  }{\bLoc =42}
% \]
% validating the transformation of the first thread to:
% \[ \bLoc \GETS 42 \SEMI \aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc \SEMI \]
% from which the required execution follows.








% Our approach has two key ingredients.  

% First, we focus on \emph{multi-copy atomicity} (\mca), which holds that when
% a write becomes visible to one thread it must become visible to
% all\nofootnote{\mca\ is traditionally explored in hardware memory models.
%   \tso\ (see, e.g.~\cite{DBLP:journals/cacm/SewellSONM10}) and recent
%   architectures, such as \armeight\ (see,
%   e.g.~\cite{DBLP:journals/pacmpl/PulteFDFSS18}), are \mca, but not older
%   architectures, such as \ppc\ (see, e.g.~\cite{DBLP:conf/pldi/SarkarSAMW11})
%   or \armseven\ (see, e.g.~\cite{DBLP:conf/popl/AlglaveFIMSSN09}).}
% \citep{DBLP:journals/pacmpl/PulteFDFSS18}.  As envisioned in
% \cite[\textsection3.3]{AlglaveThesis}, this allows us to capture cross-thread
% dependencies in a single partial order.  The key insight is that \emph{\mca{}
%   permits a single, global notion of time, manifest in the pomset order}.
% This is a dramatic simplification over other models.
% % acyclicity of the pomset providing a global notion of time.  Just as \mca{}
% % dramatically simplifies the programmer model for
% % hardware, % \citep{DBLP:journals/pacmpl/PulteFDFSS18},
% % this global notion of time dramatically simplifies our model for the language
% % level.
% % As far as we are aware, ours is the first language-level model to capture \mca.   The appeal of \mca{} in hardware is the dramatically simpler programmer model \citep{DBLP:journals/pacmpl/PulteFDFSS18}.  We believe it has the same appeal at the language-level.  

% Second, we weaken the program-order within a thread to capture only
% \emph{essential dependencies}.  These are represented in the pomset order.
% This reduction from program order to pomset order is similar to the reduction
% to \emph{preserved} program order (\textsf{ppo}) in hardware models.  However, rather
% than calculating dependencies syntactically, we compute them using 
% %Previous language models have used syntactic notions of dependency \cite{Batty:2011:MCC:1926385.1926394}.
% classical Hoare logic. The key insight is that \emph{logic is better than syntax}.
% Consider the following program fragments: %\begingroup \allowdisplaybreaks
% \begin{align*}
%   & \aCmd_1: \aLoc \GETS 1 \SEMI \bLoc \GETS 1
%   \\[-1ex] & \aCmd_2: \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN\ \bLoc \GETS 1 \ELSE \bLoc \GETS 1  \FI
%   \\[-1ex] & \aCmd_3: \aLoc \GETS 1 \SEMI \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN \bLoc \GETS 1 \FI
%   %\\[-1ex] &\aCmd_4:  \bLoc \GETS 1 \SEMI \aLoc \GETS 1
% \end{align*}
% %\endgroup
% All these fragments satisfy  $\hoare{\TRUE}{\aCmd_i}{\bLoc =1}$; thus, in each case, the write of $y$ is independent of
% any code that precedes it in program order.  This allows a compiler or processor to reorder the write with respect to the code that precedes it\nofootnote{IN RELATED Thus, the model fully reaps the benefits of viewing a memory model in terms of (sequential) program transformations, eg. see~\citep{Saraswat:2007:TMM:1229428.1229469,DBLP:conf/fm/LahavV16,
% DBLP:conf/popl/DemangeLZJPV13,DBLP:conf/esop/FerreiraFS10}, without explicitly being formalized as such.}.


In \textsection\ref{sec:model} and \textsection\ref{sec:refine}, we define the model.  We show that the model:
\begin{itemize}
\item validates expected litmus cases and compiler optimizations
  (\textsection\ref{sec:props}-\ref{sec:refine}).

\item captures all C11 concurrency features  %, including relaxed, release-acquire and SC atomics, fences, and RMW
  (\textsection\ref{sec:variants}),

\item allows compositional reasoning for temporal safety, disallowing \oota{} behavior %properties
  (\textsection\ref{sec:logic}),

\item is implementable on \armeight/\tso\ {\em without} extra synchronization for
  relaxed access\nofootnote{Compilation to \armseven\ or \ppc\
    requires extra synchronization.} (\textsection\ref{sec:arm}), and

\item  satisfies the \emph{local} \drfsc\ criterion \cite{Dolan:2018:BDR:3192366.3192421} (\textsection\ref{sec:sc}).

\end{itemize}
We conclude by discussing relating work (\textsection\ref{sec:related}) and limitations (\textsection\ref{sec:limits}).


\citet{Batty17} observed that ``the current crop of relaxed memory models can
only be used to calculate the behavior of a whole program\ldots'' and argued
that instead, we should ``consider a program as an aggregate of components
over different models, composed together.''  Our work is inspired by this
call for \emph{compositionality} in models of relaxed concurrency.

Our model is compositional in the normal sense of a denotational semantics:
for example, the denotation $\sem{C^1\!{\PAR}\! C^2}$ is computed from
$\sem{C^1}$ and $\sem{C^2}$.  The model obeys laws such as scope
extrusion---$\sem{\aCmd\!{\PAR}\! \VAR\aLoc\SEMI\bCmd} =
\sem{\VAR\aLoc\SEMI(\aCmd\!{\PAR}\!\bCmd)}$ when $\aLoc\not\in\free(\aCmd)$---and
case analysis---$\sem{\aCmd} = \sem{\IF{\aExp}\THEN\aCmd\ELSE\aCmd\FI}$.
This kind of algebraic reasoning is not supported by current models.

Our model also supports compositional reasoning about \emph{data races}
(\textsection\ref{sec:sc}), isolating races in space and time.  Spatial
separation ensures that a race on one location does not invalidate \drfsc{}
at other locations.  Temporal separation ensures that \drfsc{} can be applied
within a properly synchronized region, unaffected by races that precede or
follow.

Finally, our model supports compositional reasoning about \emph{temporal
  safety properties} (\textsection\ref{sec:logic}).  Consider that each
thread of \ref{OOTA4} satisfies the following invariant: \emph{A write of $1$
  to $y$ must be preceded by a read of $1$ from $x$, and if $1$ is written to
  $z$ then a write of $1$ to $x$ must be preceded by a read of $1$ from $y$.}
Compositionality allows us to conclude that whole program satisfies this
property.  This reasoning fails in
\cite{DBLP:conf/popl/KangHLVD17,DBLP:conf/esop/JagadeesanPR10,DBLP:journals/pacmpl/ChakrabortyV19},
demonstrating a lack of compositionality.






% The executions of a program are computed compositionally, by induction on the
% structure of the program.  Thus, our model falls into the style of relaxed
% memory models advocated by~\citet{Batty17}.  Combined with a single global
% order on events, compositionality helps explain how our model disallows
% \oota{} execution.  After all, compositionality states that parallel
% composition does not create unexpected
% behaviors.  % The fact that the dependency relation is a partial order forbids
% % \oota\ behaviors.  
% % The simplest \oota{} litmus test is the following variant of \eqref{OOTA?}
% % and \ref{OOTA1}---without $z$ or
% % the conditional.  Again all memory locations are initialized to $0$:
% % % asks whether either of the following threads
% % % can see non-zero values:
% % \begin{gather*}
% %   \tag{\ref{OOTA3}}
% %   %x\GETS0\SEMI y\GETS0\SEMI
% %   %(\bLoc \GETS \aLoc \PAR \aLoc \GETS \bLoc)
% %   \bLoc \GETS \aLoc \PAR r\GETS y\SEMI x\GETS r  
% % \end{gather*}
% We rule out $z=1$ in \ref{OOTA3}--\ref{OOTA4} as follows: The write of
% $\bLoc$ on the left hand side is dependent on the read to $\aLoc$.  If the
% program writes $z$, then the write of $\aLoc$ on the right is dependent on
% the read to $\bLoc$.  Since a non-zero read can only be satisfied externally,
% both reads are part of the dependency order, leading to a cycle.  Such a
% cycle contradicts the assumption that dependency forms a partial order.  We
% formalize this argument in \textsection\ref{sec:logic}.




% In the main paper, we present the model, examples, the results concerning
% compositional reasoning  and optimization, and a discussion of
% related work.  
%The details of \armeight/\tso-compilation may be found in the appendix.

% On the last point, we demonstrate a further completeness result.  Whereas the JMM aims to validate {\em all} sequential optimizations, it is clear that is impossible.  For example, the introduction of redundant reads  but not valid concurrently. Thus, $\aReg \GETS \REF{\aLoc} \SEMI \IF{\aReg != \aReg} \cLoc \GETS 1 \FI$ cannot be replaced by $\aReg \GETS \aLoc \SEMI \bReg \GETS \aLoc  \SEMI 
% \IF{\aReg != \bReg} \THEN \cLoc \GETS 1 \FI$.  

% Our model does the best possible under these constraints.   Call a program fragment ``linear'' if it does at most one read and at most one write on any location in any execution.  Thus, the context is unable to interfere with the atomic execution of the command; dually, neither can the atomic execution of the command interfere with the context.  We show that if sequential and synchronization free $\aCmd$ and $\bCmd$ are sequentially equivalent, and furthermore $\bCmd$ is ``'linear'' in this sense, then $\aCmd$ can be validly replaced by $\bCmd$.  
% Similarly, for redundant writes; $\aLoc \GETS 1$ cannot be 
% replaced by $\aLoc \GETS 1 \SEMI \aLoc \GETS 1 $ in a model 
% with coherence.





%\paragraph*{Rest of the paper. }  We begin with an informal introduction to the modeling ideas in \textsection\ref{sec:model:intro}, developing the precise formalities in \textsection\ref{sec:model}.   \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.  \textsection\ref{sec:examples}.develops more illustrative examples.  We address related work in \textsection\ref{sec:ldrf} and conclude after.  An appendix contains details of proofs and further examples.

% We give an informal introduction to the model in \textsection\ref{sec:model:intro} before presenting the precise formalities in \textsection\ref{sec:model}.
% \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.
% We %present additional examples in \textsection\ref{sec:examples} and
% end with
% a discussion of related work in \textsection\ref{sec:ldrf}.
% An appendix
% contains details of proofs and further examples.


\endinput

To the reader interested in models that forbid load buffering, we provide a way to adapt our model to forbid the relaxing of the program order from reads to writes, thus modeling~\cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA}.  Our new contributions for such a reader are an approach to validating data-sensitive compiler optimizations and compositional reasoning of temporal properties.   


We illustrate the last criterion with two examples.   
First, consider the well-known ``Out Of Thin Air'' (\oota) litmus test, with all variables initialized to $0$:
\begin{equation}
  %x\GETS0\SEMI y\GETS0\SEMI
  (y\GETS x \PAR x \GETS y)
\end{equation}
Informally, both threads satisfy the invariant that conjoins ``A write of 1  to x  requires a prior read  of 1 from y'' and ``A write of 1  to y  requires a prior read  of 1 from x ''.  If composition holds, the full program satisfies the invariant.  Since the variable declaration closes the program from other writes to $x,y$, we  deduce the conjunction of  ``A write of 1  to x  requires a prior write  of 1 to x'' and ``A write of 1  to y  requires a prior write  of 1 from x'' . Thus, we deduce that ``A write of 1  to x  requires a prior write  of 1 to x'', and consequently ``there is no write of 1 to x''. 

provides an  {\em objectively  falsifiable} measurement of \oota\ in a memory model. 



