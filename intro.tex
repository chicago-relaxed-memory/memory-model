\section{Introduction}
\label{sec:intro}
\citet{Manson:2005:JMM:1047659.1040336} identify the central problem in the
design of software relaxed memory models: ``The memory model must strike a
balance between ease-of-use for programmers and implementation flexibility
for system designers.''  

%In order to sharpen the criteria to evaluate memory models, we first outline desiderata  that concretize the above prescription.  

There are  two aspects to ``ease of use.''  First, the expectation of
\emph{sequential consistency for data race free programs}
(\drfsc)~\cite{DBLP:journals/tpds/AdveH93, DBLP:conf/isca/AdveH90} permits
the programmer to forget about relaxed memory for correctly synchronized
programs.  Second, all programs---even those with data races---should support
compositional reasoning on temporal safety
properties~\cite{PnueliSafety,Misra:1981:PNP:1313338.1313770,StarkSafety,Abadi:1993:CS:151646.151649}.

There are also two aspects of ``implementation flexibility.''  First, relaxed
atomic access should not require hardware synchronization.  Second, the model
should facilitate compiler transformations, such as the reordering of independent
statements; ideally the model should support all valid optimizations of
synchronization\hyp{}free single\hyp{}threaded code.
% A
% canonical example is that independent statements should commute.

Sailing between this Scylla and Charybdis has proven very difficult.  Three
lines of code can leave the top experts in the field flabbergasted.  The
solutions that have been proposed are understandable to mechanical proof
assistants, but humans have been left behind.

In this paper, we combine two ideas that humans can understand: \emph{preconditions}
\cite{Hoare:1969:ABC:363235.363259} and \emph{labelled partial orders} (aka \emph{pomsets})
\cite{GISCHER1988199,Plotkin:1997:TSP:266557.266600}.  The resulting model
mostly satisfies the desiderata.  We sacrifice only implementability on
``non-\mca'' processors, such as \ppc\ and \armseven{}. As a result, however,
there is only one order relation to visualize.

Perhaps you believe the problem has already been solved?  Let us try to
convince you otherwise.
% Eventually,
% the enthusiasm of proposing a new model yields to weariness as the
% complications mount.

To get a sense of the problems involved,
% \citeauthor{DBLP:journals/toplas/Lochbihler13}'s example shows a surprising feature of
% relaxed memory models: the presence of an execution may depend on code that was not executed. Consider:
consider that the existence of an execution in a relaxed memory model may
depend on code that was \emph{not} executed. Let $r$ and $s$ be registers and
$x$-$z$ be shared memory locations.  Consider:
\begin{gather}
  \tag{\ref{OOTA?}}
    y\GETS x
  \PAR
  r\GETS y\SEMI\IF{r}\THEN 
  x\GETS r\SEMI z\GETS r \ELSE x\GETS1 \FI
\end{gather}
Most programmers would be surprised to learn that this program does allow an
execution in which $z=1$. To see why, imagine that a compiler does type
inference and finds that $x$ and $y$ are booleans, with value either $0$ or
$1$.  This enables the program to be optimized to the following:
\begin{gather*}
  %\taglabelp{OOTA?}
    y\GETS x
  \PAR
  r\GETS y\SEMI\IF{r}\THEN 
  x\GETS 1\SEMI z\GETS 1 \ELSE x\GETS1 \FI
\end{gather*}
Since $x\GETS1$ occurs in both branches of the conditional, the compiler can
then lift it, and reorder with the independent read of $y$, yielding:
\begin{gather*}
  %\taglabelpp{OOTA?}
    y\GETS x
  \PAR
  x\GETS1\SEMI
  r\GETS y\SEMI\IF{r}\THEN z\GETS 1 \FI
\end{gather*}
Then $z=1$ at then end of an execution where the first thread is interleaved
immediately after executing $x\GETS1$.  Compare \eqref{OOTA?} with:
\begin{gather}
  \tag{\ref{OOTA!}}
    y\GETS x
  \PAR
  r\GETS y\SEMI \IF{r}\THEN 
  x\GETS r\SEMI z\GETS r \ELSE x\GETS2 \FI
\end{gather}
which has a similar execution where $z=2$, but does not have an execution
where $z=1$. Note that the only difference between \eqref{OOTA?} and
\eqref{OOTA!} is the code in the branch that was not taken. This means that
any model of relaxed memory that supports common compiler optimizations (such
as the transformations above) must take into account code that was not
executed. This is why most relaxed memory models include some form of
speculative execution.



\citeauthor{DBLP:conf/java/Pugh99} [\citeyear{DBLP:conf/java/Pugh99},
\textsection2.3] initiated the modern study of relaxed memory by noting that
Java 1.1 failed to validate Common Subexpression Elimination (CSE) in the
presence of aliasing. For example, given that $\aReg_2\neq\bReg$, is it valid
to transform the program on the left to that on the right?
\begin{align*}
  %\tag{\ref{CSE}}
  ({r_1\GETS \aLoc \SEMI
  s\GETS \bLoc \SEMI  
  r_2\GETS \aLoc\SEMI\aCmd})
&&
  ({r_1\GETS \aLoc \SEMI     
    r_2\GETS r_1\SEMI
    s\GETS \bLoc \SEMI\aCmd})
\end{align*}
The resulting Java Memory Model (JMM) \cite{Manson:2005:JMM:1047659.1040336}
greatly advanced the state of the art.


\citeauthor{DBLP:journals/toplas/Lochbihler13}'s
[\citeyear{DBLP:journals/toplas/Lochbihler13}] monumental study of the JMM
revealed a surprising limitation: The following program ``is type correct if
it declares $x$, $y$ and $r$ of type \texttt{D}. However, it has a legal
execution where they reference a \texttt{C} object''
\citep[Fig.~8]{DBLP:journals/toplas/Lochbihler13}:
%\vspace{-.5ex}
\begin{gather}
  \taglabel{OOTA1}
  z \GETS 1
  \PAR %\\[-1ex] \PAR&
  y\GETS x
  \PAR
  \aReg\GETS y \SEMI \IF{z} \THEN \bReg \GETS \NEW \texttt{C} \ELSE \aReg \GETS \NEW \texttt{D} \FI  \SEMI x \GETS \aReg 
\end{gather}
Informally, all threads satisfy the invariant ``allocation at type \texttt{C}
is preceded by reading $1$ for $z$'' and ``allocation at type \texttt{D} is
preceded by reading $0$ for $z$.''  If composability of safety properties were to hold,
the full program would satisfy both invariants.  The lack of composability
forced \citeauthor{DBLP:journals/toplas/Lochbihler13} to partition memory by
type in order to prove type safety.  This formal device means that memory
cannot be used at different types over time, making practical memory
reclamation impossible.

% The JMM is defined using an operational model that incorporates the idea of
% restarting executions.  Similar models have used speculation
% \cite{DBLP:conf/esop/JagadeesanPR10} or promises
% \cite{DBLP:conf/popl/KangHLVD17}.

% Whereas the JMM was designed with these two aims,
As confirmed by \cite{kang,soham}, the promising semantics
\cite{DBLP:conf/popl/KangHLVD17} and related models
\citep{DBLP:conf/esop/JagadeesanPR10,DBLP:journals/pacmpl/ChakrabortyV19} all
invalidate compositional reasoning, as in \ref{OOTA1}.  (Specifically, they
allow the variant \ref{OOTA4} given in \textsection\ref{sec:logic}.)
% See
% \textsection\ref{sec:promising} for confirmation from the authors themselves.
This means that these models \emph{cannot support both type safety and
  realistic memory reclamation}.


% Due to the shortcomings of the JMM, many subsequent models preferred an
% axiomatic approach.  
The C11 Memory Model \cite{Batty:2011:MCC:1926385.1926394} does not attempt
to validate CSE, at least not for relaxed atomic access (consider the case
where $x$ and $y$ are aliased above).  C11 \emph{does} allow the
transformation for \emph{plain} access, but this comes with the threat of
\emph{undefined behavior} should any plain access ever possibly engage in a
data race \cite{undefined}.  C11 also allows values that arise ``Out Of Thin
Air'' (\oota) \cite{DBLP:conf/esop/BattyMNPS15}, exploiting causality cycles.
Undefined and \oota{} behaviors are antithetical to the goals of safe
languages.
% Thus the folklore belief that ``every substantial C program has
% undefined behavior.''


%to permit us to reason separately about individual threads validating safety properties. 
% ``Out Of Thin Air'' (\oota) executions invalidate the 
% composability  of safety properties.

% None of the extant memory models validate both
% ``implementation flexibility'' and ``ease of use.''  This paper provides a
% solution.  The solution is remarkably simple, enriching labelled partial
% orders (aka \emph{pomsets}) with preconditions.

Strong models, including Sequential Consistency
(SC)~\citep{Lamport:1979:MMC:1311099.1311750}, RC11
\citep{DBLP:conf/pldi/LahavVKHD17}, and others
\citep{Dolan:2018:BDR:3192366.3192421,DBLP:conf/pldi/LahavVKHD17,DBLP:conf/lics/JeffreyR16,Boehm:2014:OGA:2618128.2618134}
support compositional reasoning.  However, all of these models invalidate
reordering of independent statements.  Several require fences after relaxed
reads, even on \armeight.
% \cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA,DBLP:conf/lics/JeffreyR16} forbid breaking of the program order from reads to writes and thus require extra fences after read actions in hardware implementations.
% \citep{Boehm:2014:OGA:2618128.2618134} show that the RC11 model %\cite{DBLP:conf/pldi/LahavVKHD17}
% forces a dependency or a fence between a relaxed atomic read and a subsequent relaxed atomic write.  


\myparagraph{Our Model}

In our approach, a program is a set of executions.  Each execution is a
partial order on a set of read and write events.  The order is intended to be
read as a ``dependency'' relation.  The dependency relation can vary between
executions, so it is dynamic; events that are not related in an execution are
``independent'' and can be seen by a sequential observer in either order.

Cross thread dependencies arise from conflicting actions on the same
variable: Roughly, we order any two actions on the same location, at least
one of which is a write.  In the parlance of hardware memory
models~\citep{alglave}: $\rcoe$, $\rfre$, and $\rrfex$ are included in the
global dependency ordering.  Thus, our model realizes \emph{multi-copy
  atomicity} (\mca): when a write becomes visible to one thread it must
become visible to all\nofootnote{\mca\ is traditionally explored in hardware
  memory models.  \tso\ (see, e.g.~\cite{DBLP:journals/cacm/SewellSONM10})
  and recent architectures, such as \armeight\ (see,
  e.g.~\cite{DBLP:journals/pacmpl/PulteFDFSS18}, RISC-V.  ), are \mca, but
  not older architectures, such as \ppc\ (see,
  e.g.~\cite{DBLP:conf/pldi/SarkarSAMW11}) or \armseven\ (see,
  e.g.~\cite{DBLP:conf/popl/AlglaveFIMSSN09}).}
\citep{DBLP:journals/pacmpl/PulteFDFSS18}.  As envisioned in
\cite[\textsection3.3]{AlglaveThesis}, this allows us to capture cross-thread
dependencies in a single partial order.

Our key insight is that \emph{\mca{} permits a single, global notion of time,
  manifest in the pomset order}.
  

Within a thread, the dependency calculation can be viewed as the computation
of \emph{preserved} program order ($\rppo$) in hardware models.  $\rppo$
captures the \emph{essential dependencies} between events in the same thread.
Consider the following program fragments: \begingroup \allowdisplaybreaks
\begin{align*}
  & \aCmd_1: \aLoc \GETS 1 \SEMI \bLoc \GETS 1
  \\[-1ex] & \aCmd_2: \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN\ \bLoc \GETS 1 \ELSE \bLoc \GETS 1  \FI
  \\[-1ex] & \aCmd_3: \aLoc \GETS 1 \SEMI \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN \bLoc \GETS 1 \FI
  %\\[-1ex] &\aCmd_4:  \bLoc \GETS 1 \SEMI \aLoc \GETS 1
\end{align*}
\endgroup
All these fragments satisfy $\hoare{\TRUE}{\aCmd_i}{\bLoc =1}$; thus, in each
case, the write of $y$ is independent of any code that precedes it in program
order. While $\aCmd_1$ reflects syntactic independence, $\aCmd_2$ reflects
the independence derived by case analysis, and $\aCmd_3$ reflects the
independence deduced from partial evaluation (in the restricted form of
constant propagation).

Our key insight is to that \emph{logic is better than syntax} to capture such
dependencies.

The logical perspective provides a clear intuition as to why certain compiler
transformations should be valid.  Such intuitions are not always readily
available in relaxed memory models.  For example, \emph{value range
  analysis}---used in the discussion of \eqref{OOTA?}---is very difficult in
many models.  As another example, models such as \armeight{} distinguish
\emph{internal} reads, which are fulfilled by a write of the same thread,
from \emph{external} ones.  Unlike externally fulfilled reads, internal reads
are not necessarily recorded in the dependency relation.  As exemplified by
$\aCmd_3$, this allows a compiler to reorder the fulfilling write with
subsequent code that depends on the read.  Neither value range analysis nor
internal reads require special treatment in our model.



% The logical perspective provides a clear intuition as to why our model validates
% the compiler transformations discussed above \eqref{OOTA?}.
% reordering of independent statements, Irrelevant read introduction, RaR, RaW,
% WaW and Read Reordering and motivates the expressivity wrt the \jmm\
% causality test cases.  For example, consider Test Case 17 from Pugh.
% \[
% \begin{array}{ll}
%  &\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc \SEMI \bLoc \GETS \aReg_1  \\
%  \PAR & \aReg_2 \GETS \bLoc \SEMI \aLoc \GETS \aReg 
% \end{array}
% \]
% \jmm\ permits the behavior $\aReg_1 = \aReg_2 = \aReg_3 =42$.

% We deduce:
% \[
% \hoare{\TRUE}{\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc }{\aReg_1 =42}
% \]
% and so:
% \[
% \hoare{\TRUE}{\aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc  \SEMI \bLoc \GETS \aReg_1  }{\bLoc =42}
% \]
% validating the transformation of the first thread to:
% \[ \bLoc \GETS 42 \SEMI \aReg_3 \GETS \aLoc \SEMI \IF{\aReg_3 \neq 42} \THEN \aLoc \GETS 42  \FI \SEMI \aReg_1 \GETS \aLoc \SEMI \]
% from which the required execution follows.

The executions of a program are computed compositionally, by induction on the
structure of the program.  Thus, our model falls into the style of relaxed
memory models advocated by~\citet{Batty17}.  Combined with a single global
order on events, compositionality helps explain how our model disallows
\oota{} execution.  After all, compositionality states that parallel
composition does not create unexpected
behaviors.  % The fact that the dependency relation is a partial order forbids
% \oota\ behaviors.  
The simplest \oota{} litmus test asks whether either of the following threads
can see non-zero values:
\begin{gather*}
  \tag{\ref{OOTA3}}
  x\GETS0\SEMI y\GETS0\SEMI
  (\bLoc \GETS \aLoc \PAR \aLoc \GETS \bLoc)
\end{gather*}
We rule out non-zero reads as follows: The write of $\bLoc$ on the left hand
side is dependent on the read to $\aLoc$.  Similarly, the write of $\aLoc$ on
the right is dependent on the read to $\bLoc$.  Since a non-zero read can
only be satisfied externally, both reads are part of the dependency order,
leading to a cycle.  Such a cycle contradicts the assumption that dependency
forms a partial order.  We discuss \ref{OOTA1} in \textsection\ref{sec:logic}.







% Our approach has two key ingredients.  

% First, we focus on \emph{multi-copy atomicity} (\mca), which holds that when
% a write becomes visible to one thread it must become visible to
% all\nofootnote{\mca\ is traditionally explored in hardware memory models.
%   \tso\ (see, e.g.~\cite{DBLP:journals/cacm/SewellSONM10}) and recent
%   architectures, such as \armeight\ (see,
%   e.g.~\cite{DBLP:journals/pacmpl/PulteFDFSS18}), are \mca, but not older
%   architectures, such as \ppc\ (see, e.g.~\cite{DBLP:conf/pldi/SarkarSAMW11})
%   or \armseven\ (see, e.g.~\cite{DBLP:conf/popl/AlglaveFIMSSN09}).}
% \citep{DBLP:journals/pacmpl/PulteFDFSS18}.  As envisioned in
% \cite[\textsection3.3]{AlglaveThesis}, this allows us to capture cross-thread
% dependencies in a single partial order.  The key insight is that \emph{\mca{}
%   permits a single, global notion of time, manifest in the pomset order}.
% This is a dramatic simplification over other models.
% % acyclicity of the pomset providing a global notion of time.  Just as \mca{}
% % dramatically simplifies the programmer model for
% % hardware, % \citep{DBLP:journals/pacmpl/PulteFDFSS18},
% % this global notion of time dramatically simplifies our model for the language
% % level.
% % As far as we are aware, ours is the first language-level model to capture \mca.   The appeal of \mca{} in hardware is the dramatically simpler programmer model \citep{DBLP:journals/pacmpl/PulteFDFSS18}.  We believe it has the same appeal at the language-level.  

% Second, we weaken the program-order within a thread to capture only
% \emph{essential dependencies}.  These are represented in the pomset order.
% This reduction from program order to pomset order is similar to the reduction
% to \emph{preserved} program order (\textsf{ppo}) in hardware models.  However, rather
% than calculating dependencies syntactically, we compute them using 
% %Previous language models have used syntactic notions of dependency \cite{Batty:2011:MCC:1926385.1926394}.
% classical Hoare logic. The key insight is that \emph{logic is better than syntax}.
% Consider the following program fragments: %\begingroup \allowdisplaybreaks
% \begin{align*}
%   & \aCmd_1: \aLoc \GETS 1 \SEMI \bLoc \GETS 1
%   \\[-1ex] & \aCmd_2: \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN\ \bLoc \GETS 1 \ELSE \bLoc \GETS 1  \FI
%   \\[-1ex] & \aCmd_3: \aLoc \GETS 1 \SEMI \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN \bLoc \GETS 1 \FI
%   %\\[-1ex] &\aCmd_4:  \bLoc \GETS 1 \SEMI \aLoc \GETS 1
% \end{align*}
% %\endgroup
% All these fragments satisfy  $\hoare{\TRUE}{\aCmd_i}{\bLoc =1}$; thus, in each case, the write of $y$ is independent of
% any code that precedes it in program order.  This allows a compiler or processor to reorder the write with respect to the code that precedes it\nofootnote{IN RELATED Thus, the model fully reaps the benefits of viewing a memory model in terms of (sequential) program transformations, eg. see~\citep{Saraswat:2007:TMM:1229428.1229469,DBLP:conf/fm/LahavV16,
% DBLP:conf/popl/DemangeLZJPV13,DBLP:conf/esop/FerreiraFS10}, without explicitly being formalized as such.}.


In \textsection\ref{sec:model} and \textsection\ref{sec:refine}, we define the model.  We show that the model:
\begin{itemize}
\item validates expected litmus cases and compiler optimizations
  (\textsection\ref{sec:props}-\ref{sec:refine}).

\item captures all C11 concurrency features  %, including relaxed, release-acquire and SC atomics, fences, and RMW
  (\textsection\ref{sec:variants}),

\item allows compositional reasoning for safety, disallowing \oota{} behavior %properties
  (\textsection\ref{sec:logic}),

\item is implementable on \armeight/\tso\ {\em without} extra synchronization for
  relaxed access\nofootnote{Compilation to \armseven\ or \ppc\
    requires extra synchronization.} (\textsection\ref{sec:arm}), and

\item  satisfies the \emph{local} \drfsc\ criterion \cite{Dolan:2018:BDR:3192366.3192421} (\textsection\ref{sec:sc}).

\end{itemize}
We conclude by discussing relating work (\textsection\ref{sec:related}) and limitations (\textsection\ref{sec:limits}).
% In the main paper, we present the model, examples, the results concerning
% compositional reasoning  and optimization, and a discussion of
% related work.  
%The details of \armeight/\tso-compilation may be found in the appendix.

% On the last point, we demonstrate a further completeness result.  Whereas the JMM aims to validate {\em all} sequential optimizations, it is clear that is impossible.  For example, the introduction of redundant reads  but not valid concurrently. Thus, $\aReg \GETS \REF{\aLoc} \SEMI \IF{\aReg != \aReg} \cLoc \GETS 1 \FI$ cannot be replaced by $\aReg \GETS \aLoc \SEMI \bReg \GETS \aLoc  \SEMI 
% \IF{\aReg != \bReg} \THEN \cLoc \GETS 1 \FI$.  

% Our model does the best possible under these constraints.   Call a program fragment ``linear'' if it does at most one read and at most one write on any location in any execution.  Thus, the context is unable to interfere with the atomic execution of the command; dually, neither can the atomic execution of the command interfere with the context.  We show that if sequential and synchronization free $\aCmd$ and $\bCmd$ are sequentially equivalent, and furthermore $\bCmd$ is ``'linear'' in this sense, then $\aCmd$ can be validly replaced by $\bCmd$.  
% Similarly, for redundant writes; $\aLoc \GETS 1$ cannot be 
% replaced by $\aLoc \GETS 1 \SEMI \aLoc \GETS 1 $ in a model 
% with coherence.





%\paragraph*{Rest of the paper. }  We begin with an informal introduction to the modeling ideas in \textsection\ref{sec:model:intro}, developing the precise formalities in \textsection\ref{sec:model}.   \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.  \textsection\ref{sec:examples}.develops more illustrative examples.  We address related work in \textsection\ref{sec:ldrf} and conclude after.  An appendix contains details of proofs and further examples.

% We give an informal introduction to the model in \textsection\ref{sec:model:intro} before presenting the precise formalities in \textsection\ref{sec:model}.
% \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.
% We %present additional examples in \textsection\ref{sec:examples} and
% end with
% a discussion of related work in \textsection\ref{sec:ldrf}.
% An appendix
% contains details of proofs and further examples.


\endinput

To the reader interested in models that forbid load buffering, we provide a way to adapt our model to forbid the relaxing of the program order from reads to writes, thus modeling~\cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA}.  Our new contributions for such a reader are an approach to validating data-sensitive compiler optimizations and compositional reasoning of temporal properties.   


We illustrate the last criterion with two examples.   
First, consider the well-known ``Out Of Thin Air'' (\oota) litmus test, with all variables initialized to $0$:
\begin{equation}
  %x\GETS0\SEMI y\GETS0\SEMI
  (y\GETS x \PAR x \GETS y)
\end{equation}
Informally, both threads satisfy the invariant that conjoins ``A write of 1  to x  requires a prior read  of 1 from y'' and ``A write of 1  to y  requires a prior read  of 1 from x ''.  If composition holds, the full program satisfies the invariant.  Since the variable declaration closes the program from other writes to $x,y$, we  deduce the conjunction of  ``A write of 1  to x  requires a prior write  of 1 to x'' and ``A write of 1  to y  requires a prior write  of 1 from x'' . Thus, we deduce that ``A write of 1  to x  requires a prior write  of 1 to x'', and consequently ``there is no write of 1 to x''. 

provides an  {\em objectively  falsifiable} measurement of \oota\ in a memory model. 



