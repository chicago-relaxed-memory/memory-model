\section{Introduction}
\label{sec:intro}
\citet{Manson:2005:JMM:1047659.1040336} identify the central problem in the
design of software relaxed memory models: ``The memory model must strike a
balance between ease-of-use for programmers and implementation flexibility
for system designers.''  

%In order to sharpen the criteria to evaluate memory models, we first outline desiderata  that concretize the above prescription.  

There are two aspects of ``implementation flexibility.''  First, relaxed
atomic access should not require hardware synchronization.  Second, the model
should facilitate compiler transformations, such as the reordering of independent
statements; ideally the model should support all valid optimizations of
synchronization\hyp{}free single\hyp{}threaded code.
% A
% canonical example is that independent statements should commute.

There are also two aspects to ``ease of use.''  First, the \emph{data race
  free-sequentially consistent} (\drfsc)
criterion~\cite{DBLP:journals/tpds/AdveH93, DBLP:conf/isca/AdveH90} permits
the programmer to forget about relaxed memory for correctly synchronized
programs.  Second, all programs---even those with data races---should support
compositional reasoning on temporal safety
properties~\cite{PnueliSafety,Misra:1981:PNP:1313338.1313770,StarkSafety,Abadi:1993:CS:151646.151649}.

Sailing between this Scylla and Charybdis has proven very difficult.  Three
lines of code can leave the top experts in the field flabbergasted.  The
solutions that have been proposed are understandable to mechanical proof
assistants, but humans have been left behind.

In this paper, we combine two ideas that humans can understand: \emph{preconditions}
\cite{Hoare:1969:ABC:363235.363259} and \emph{labelled partial orders} (aka \emph{pomsets})
\cite{GISCHER1988199,Plotkin:1997:TSP:266557.266600}.  The resulting model
mostly satisfies the desiderata.  We sacrifice only implementability on
``non-\mca'' processors, such as \ppc\ and \armseven{}. As a result, however,
there is only one order relation to visualize.

Perhaps you believe the problem has already been solved?  Let us try to
convince you otherwise.
% Eventually,
% the enthusiasm of proposing a new model yields to weariness as the
% complications mount.

\citeauthor{DBLP:conf/java/Pugh99} [\citeyear{DBLP:conf/java/Pugh99},
\textsection2.3] initiated the modern study of relaxed memory by noting that
Java 1.1 failed to validate Common Subexpression Elimination (CSE) in the
presence of aliasing. For example, given that $\aReg_2\neq\bReg$, is it valid
to transform the program on the left to that on the right?
\begin{align*}
\tag{CSE}\label{CSE1}
  ({r_1\GETS \aLoc \SEMI
  s\GETS \bLoc \SEMI  
  r_2\GETS \aLoc\SEMI\aCmd})
&&
  ({r_1\GETS \aLoc \SEMI     
    r_2\GETS r_1\SEMI
    s\GETS \bLoc \SEMI\aCmd})
\end{align*}
The resulting Java Memory Model (JMM) \cite{Manson:2005:JMM:1047659.1040336}
greatly advanced the state of the art.

\citeauthor{DBLP:journals/toplas/Lochbihler13}'s
[\citeyear{DBLP:journals/toplas/Lochbihler13}] monumental study of the JMM
revealed a surprising limitation: The following program ``is type correct if
it declares $x$, $y$ and $r$ of type \texttt{D}. However, it has a legal
execution where they reference a \texttt{C} object''
\citep[Fig.~8]{DBLP:journals/toplas/Lochbihler13}:
%\vspace{-.5ex}
\begin{gather}
  \taglabel{OOTA1}
  z \GETS 1
  \PAR %\\[-1ex] \PAR&
  y\GETS x
  \PAR
  \aReg\GETS y \SEMI \IF{z} \THEN \bReg \GETS \NEW \texttt{C} \ELSE \aReg \GETS \NEW \texttt{D} \FI  \SEMI x \GETS \aReg 
\end{gather}
Informally, all threads satisfy the invariant ``allocation at type \texttt{C}
is preceded by reading $1$ for $z$'' and ``allocation at type \texttt{D} is
preceded by reading $0$ for $z$.''  If composability of safety were to hold,
the full program would satisfy both invariants.  The lack of composability
forced \citeauthor{DBLP:journals/toplas/Lochbihler13} to partition memory by
type in order to prove type safety.  This formal device means that memory
cannot be used at different types over time, making practical memory
reclamation impossible.

% The JMM is defined using an operational model that incorporates the idea of
% restarting executions.  Similar models have used speculation
% \cite{DBLP:conf/esop/JagadeesanPR10} or promises
% \cite{DBLP:conf/popl/KangHLVD17}.

% Whereas the JMM was designed with these two aims,
The JMM, the promising semantics \cite{DBLP:conf/popl/KangHLVD17}, and
related models
\citep{DBLP:conf/esop/JagadeesanPR10,DBLP:journals/pacmpl/ChakrabortyV19} all
invalidate compositional reasoning, as in \ref{OOTA1}.  See
\textsection\ref{sec:promising} for confirmation from the authors themselves.
This means that these models \emph{cannot support both type safety and
  realistic memory reclamation}.

\citeauthor{DBLP:journals/toplas/Lochbihler13}'s example shows a surprising feature of
relaxed memory models: the presence of an execution may depend on code that was not executed. Consider:
\begin{gather}
  \taglabel{OOTA?}
    y\GETS x
  \PAR
    \IF{y}\THEN r\GETS y\SEMI x\GETS r\SEMI a\GETS r \ELSE x\GETS1 \FI
\end{gather}
Most programmers would be surprised to learn that this program does allow
an execution in which $a=1$. To see why, imagine a compiler that does type inference
and finds that $x$ and $y$ are booleans, with either value $0$ or $1$. which enables the
program to be optimized as:
\begin{gather}
  \taglabel{OOTA?'}
    y\GETS x
  \PAR
    \IF{y}\THEN x\GETS 1\SEMI a\GETS 1 \ELSE x\GETS1 \FI
\end{gather}
The compiler then lifts the assignment $x\GETS1$ out of the conditional
(which is valid, since it occurs on both branches):
\begin{gather}
  \taglabel{OOTA?''}
    y\GETS x
  \PAR
    x\GETS1\SEMI \IF{y}\THEN a\GETS 1 \FI
\end{gather}
The optimized program has a sequentially consistent execution with $a=1$.
Compare \ref{OOTA?} with:
\begin{gather}
  \taglabel{OOTA!}
    y\GETS x
  \PAR
    \IF{y}\THEN r\GETS y\SEMI x\GETS r\SEMI a\GETS r \ELSE x\GETS2 \FI
\end{gather}
which has an execution where $a=2$, but does not have an execution where $a=1$. Note that the only 
difference between \ref{OOTA?} and \ref{OOTA!} is the code in the branch
which was not taken. This means that any model of relaxed memory that supports
common compiler optimizations (such as those from \ref{OOTA?} to \ref{OOTA?''})
must take into account code that was not executed. This accounts for
the speculative executions common in relaxed memory models.

% Due to the shortcomings of the JMM, many subsequent models preferred an
% axiomatic approach.  
The C++ Memory Model \cite{Batty:2011:MCC:1926385.1926394} does not attempt
to validate \ref{CSE1}, at least not for relaxed atomic access (consider the
case where $x$ and $y$ are aliased above).  C++ \emph{does} allow the
transformation for \emph{plain} access, but this comes with the threat of
\emph{undefined behavior} should any plain access ever possibly engage in a
data race.  Thus the folklore belief that ``every substantial C++ program has
undefined behavior.''


%to permit us to reason separately about individual threads validating safety properties. 
% ``Out Of Thin Air'' (\oota) executions invalidate the 
% composability  of safety properties.

% None of the extant memory models validate both
% ``implementation flexibility'' and ``ease of use.''  This paper provides a
% solution.  The solution is remarkably simple, enriching labelled partial
% orders (aka \emph{pomsets}) with preconditions.

Strong models, including Sequential Consistency
(SC)~\citep{Lamport:1979:MMC:1311099.1311750}, RC11
\citep{DBLP:conf/pldi/LahavVKHD17}, and others
\citep{Dolan:2018:BDR:3192366.3192421,DBLP:conf/pldi/LahavVKHD17,DBLP:conf/lics/JeffreyR16,Boehm:2014:OGA:2618128.2618134}
support compositional reasoning.  However, all of these models invalidate
reordering of independent statements.  Several require fences after relaxed
reads, even on \armeight.
% \cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA,DBLP:conf/lics/JeffreyR16} forbid breaking of the program order from reads to writes and thus require extra fences after read actions in hardware implementations.
% \citep{Boehm:2014:OGA:2618128.2618134} show that the RC11 model %\cite{DBLP:conf/pldi/LahavVKHD17}
% forces a dependency or a fence between a relaxed atomic read and a subsequent relaxed atomic write.  




Our approach has two key ingredients.  

First, we focus on \emph{multi-copy atomicity} (\mca), which holds that when
a write becomes visible to one thread it must become visible to
all\nofootnote{\mca\ is traditionally explored in hardware memory models.
  \tso\ (see, e.g.~\cite{DBLP:journals/cacm/SewellSONM10}) and recent
  architectures, such as \armeight\ (see,
  e.g.~\cite{DBLP:journals/pacmpl/PulteFDFSS18}), are \mca, but not older
  architectures, such as \ppc\ (see, e.g.~\cite{DBLP:conf/pldi/SarkarSAMW11})
  or \armseven\ (see, e.g.~\cite{DBLP:conf/popl/AlglaveFIMSSN09}).}
\citep{DBLP:journals/pacmpl/PulteFDFSS18}.  As envisioned in
\cite[\textsection3.3]{AlglaveThesis}, this allows us to capture cross-thread
dependencies in a single partial order.  The key insight is that \emph{\mca{}
  permits a single, global notion of time, manifest in the pomset order}.
This is a dramatic simplification over other models.
% acyclicity of the pomset providing a global notion of time.  Just as \mca{}
% dramatically simplifies the programmer model for
% hardware, % \citep{DBLP:journals/pacmpl/PulteFDFSS18},
% this global notion of time dramatically simplifies our model for the language
% level.
% As far as we are aware, ours is the first language-level model to capture \mca.   The appeal of \mca{} in hardware is the dramatically simpler programmer model \citep{DBLP:journals/pacmpl/PulteFDFSS18}.  We believe it has the same appeal at the language-level.  

Second, we weaken the program-order within a thread to capture only
\emph{essential dependencies}.  These are represented in the pomset order.
This reduction from program order to pomset order is similar to the reduction
to \emph{preserved} program order (\textsf{ppo}) in hardware models.  However, rather
than calculating dependencies syntactically, we compute them using 
%Previous language models have used syntactic notions of dependency \cite{Batty:2011:MCC:1926385.1926394}.
classical Hoare logic. The key insight is that \emph{logic is better than syntax}.
Consider the following program fragments: \begingroup \allowdisplaybreaks
\begin{align*}
  & \aCmd_1: \aLoc \GETS 1 \SEMI \bLoc \GETS 1
  \\[-1ex] & \aCmd_2: \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN\ \bLoc \GETS 1 \ELSE \bLoc \GETS 1  \FI
  \\[-1ex] & \aCmd_3: \aLoc \GETS 1 \SEMI \aReg \GETS \aLoc \SEMI \IF{\aReg} \THEN \bLoc \GETS 1 \FI
  %\\[-1ex] &\aCmd_4:  \bLoc \GETS 1 \SEMI \aLoc \GETS 1
\end{align*}
\endgroup
All these fragments satisfy  $\hoare{\TRUE}{\aCmd_i}{\bLoc =1}$; thus, in each case, the write of $y$ is independent of
any code that precedes it in program order.  This allows a compiler or processor to reorder the write with respect to the code that precedes it\nofootnote{IN RELATED Thus, the model fully reaps the benefits of viewing a memory model in terms of (sequential) program transformations, eg. see~\citep{Saraswat:2007:TMM:1229428.1229469,DBLP:conf/fm/LahavV16,
DBLP:conf/popl/DemangeLZJPV13,DBLP:conf/esop/FerreiraFS10}, without explicitly being formalized as such.}.


We show that the model:
\begin{itemize}
\item captures all C11 concurrency features  %, including relaxed, release-acquire and SC atomics, fences, and RMW
  (\textsection\ref{sec:variants}),

\item allows compositional reasoning for safety %properties
  (\textsection\ref{sec:logic}),

\item compiles to \armeight\ and \tso\ {\em without} extra synchronization for relaxed-atomic access\nofootnote{Compilation to \armseven\ or \ppc\ requires extra synchronization.} (\textsection\ref{sec:arm}),

\item  satisfies the \emph{local} \drfsc\ criterion \cite{Dolan:2018:BDR:3192366.3192421} (\textsection\ref{sec:sc}), and

\item validates single-threaded compiler optimizations
  (\textsection\ref{sec:opt}).

\end{itemize}
We conclude by discussing relating work (\textsection\ref{sec:related}) and limitations (\textsection\ref{sec:limits}).
% In the main paper, we present the model, examples, the results concerning
% compositional reasoning  and optimization, and a discussion of
% related work.  
%The details of \armeight/\tso-compilation may be found in the appendix.

% On the last point, we demonstrate a further completeness result.  Whereas the JMM aims to validate {\em all} sequential optimizations, it is clear that is impossible.  For example, the introduction of redundant reads  but not valid concurrently. Thus, $\aReg \GETS \REF{\aLoc} \SEMI \IF{\aReg != \aReg} \cLoc \GETS 1 \FI$ cannot be replaced by $\aReg \GETS \aLoc \SEMI \bReg \GETS \aLoc  \SEMI 
% \IF{\aReg != \bReg} \THEN \cLoc \GETS 1 \FI$.  

% Our model does the best possible under these constraints.   Call a program fragment ``linear'' if it does at most one read and at most one write on any location in any execution.  Thus, the context is unable to interfere with the atomic execution of the command; dually, neither can the atomic execution of the command interfere with the context.  We show that if sequential and synchronization free $\aCmd$ and $\bCmd$ are sequentially equivalent, and furthermore $\bCmd$ is ``'linear'' in this sense, then $\aCmd$ can be validly replaced by $\bCmd$.  
% Similarly, for redundant writes; $\aLoc \GETS 1$ cannot be 
% replaced by $\aLoc \GETS 1 \SEMI \aLoc \GETS 1 $ in a model 
% with coherence.





%\paragraph*{Rest of the paper. }  We begin with an informal introduction to the modeling ideas in \textsection\ref{sec:model:intro}, developing the precise formalities in \textsection\ref{sec:model}.   \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.  \textsection\ref{sec:examples}.develops more illustrative examples.  We address related work in \textsection\ref{sec:ldrf} and conclude after.  An appendix contains details of proofs and further examples.

% We give an informal introduction to the model in \textsection\ref{sec:model:intro} before presenting the precise formalities in \textsection\ref{sec:model}.
% \textsection\ref{sec:sc} proves the DRF theorem, whereas \textsection\ref{sec:arm} provides a compilation into \armeight\ and \tso.  Single threaded optimizations, and the associated completeness theorems are addressed in \textsection\ref{sec:opt}.  \textsection\ref{sec:logic} describes a temporal logic, and a compositional proof principle for proving safety properties.
% We %present additional examples in \textsection\ref{sec:examples} and
% end with
% a discussion of related work in \textsection\ref{sec:ldrf}.
% An appendix
% contains details of proofs and further examples.


\endinput

To the reader interested in models that forbid load buffering, we provide a way to adapt our model to forbid the relaxing of the program order from reads to writes, thus modeling~\cite{Dolan:2018:BDR:3192366.3192421,BoehmOOTA}.  Our new contributions for such a reader are an approach to validating data-sensitive compiler optimizations and compositional reasoning of temporal properties.   


We illustrate the last criterion with two examples.   
First, consider the well-known ``Out Of Thin Air'' (\oota) litmus test, with all variables initialized to $0$:
\begin{equation}
  %x\GETS0\SEMI y\GETS0\SEMI
  (y\GETS x \PAR x \GETS y)
\end{equation}
Informally, both threads satisfy the invariant that conjoins ``A write of 1  to x  requires a prior read  of 1 from y'' and ``A write of 1  to y  requires a prior read  of 1 from x ''.  If composition holds, the full program satisfies the invariant.  Since the variable declaration closes the program from other writes to $x,y$, we  deduce the conjunction of  ``A write of 1  to x  requires a prior write  of 1 to x'' and ``A write of 1  to y  requires a prior write  of 1 from x'' . Thus, we deduce that ``A write of 1  to x  requires a prior write  of 1 to x'', and consequently ``there is no write of 1 to x''. 

provides an  {\em objectively  falsifiable} measurement of \oota\ in a memory model. 



